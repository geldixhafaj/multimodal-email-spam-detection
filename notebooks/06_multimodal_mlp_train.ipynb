# ============================================================
# NOTEBOOK 06 — MULTIMODAL CLASSIFIER (ONE CELL)
# Early fusion: [Transformer Embeddings | Structural Features] -> MLP
# ============================================================

# --- deps ---
!pip -q install -U numpy pandas scikit-learn torch
!pip -q uninstall -y datasets pyarrow

import os, json, time, sys, platform
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

from sklearn.metrics import (
    accuracy_score,
    precision_recall_fscore_support,
    roc_auc_score,
    confusion_matrix
)

print("Python:", sys.version)
print("Platform:", platform.platform())
print("Torch:", torch.__version__)
print("CUDA available:", torch.cuda.is_available())
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
if torch.cuda.is_available():
    print("GPU:", torch.cuda.get_device_name(0))

# ------------------------------------------------------------
# 1) Load embeddings (Notebook 04)
# ------------------------------------------------------------
EMB_DIR = "/content/embeddings_distilbert"
if not os.path.exists(EMB_DIR):
    raise FileNotFoundError(f"Embeddings directory not found: {EMB_DIR}. Run Notebook 04 first.")

# Choose which embedding type to use: "cls" or "mean"
EMB_TYPE = "cls"   # change to "mean" if you want to compare later

train_emb = np.load(os.path.join(EMB_DIR, f"train_{EMB_TYPE}.npy"))
val_emb   = np.load(os.path.join(EMB_DIR, f"val_{EMB_TYPE}.npy"))
test_emb  = np.load(os.path.join(EMB_DIR, f"test_{EMB_TYPE}.npy"))

y_train_e = np.load(os.path.join(EMB_DIR, "train_labels.npy"))
y_val_e   = np.load(os.path.join(EMB_DIR, "val_labels.npy"))
y_test_e  = np.load(os.path.join(EMB_DIR, "test_labels.npy"))

print("\nEmbeddings loaded:")
print("train_emb:", train_emb.shape, "y:", y_train_e.shape)
print("val_emb:  ", val_emb.shape,   "y:", y_val_e.shape)
print("test_emb: ", test_emb.shape,  "y:", y_test_e.shape)

# ------------------------------------------------------------
# 2) Load structural features (Notebook 05)
# ------------------------------------------------------------
STRUCT_DIR = "/content/struct_features"
if not os.path.exists(STRUCT_DIR):
    raise FileNotFoundError(f"Structural features directory not found: {STRUCT_DIR}. Run Notebook 05 first.")

train_struct = np.load(os.path.join(STRUCT_DIR, "train_struct.npy"))
val_struct   = np.load(os.path.join(STRUCT_DIR, "val_struct.npy"))
test_struct  = np.load(os.path.join(STRUCT_DIR, "test_struct.npy"))

y_train_s = np.load(os.path.join(STRUCT_DIR, "train_labels.npy"))
y_val_s   = np.load(os.path.join(STRUCT_DIR, "val_labels.npy"))
y_test_s  = np.load(os.path.join(STRUCT_DIR, "test_labels.npy"))

print("\nStructural features loaded:")
print("train_struct:", train_struct.shape, "y:", y_train_s.shape)
print("val_struct:  ", val_struct.shape,   "y:", y_val_s.shape)
print("test_struct: ", test_struct.shape,  "y:", y_test_s.shape)

# ------------------------------------------------------------
# 3) Sanity checks (alignment)
# ------------------------------------------------------------
def assert_alignment(aX, ay, bX, by, split_name):
    assert len(aX) == len(ay), f"{split_name}: embedding X/y length mismatch"
    assert len(bX) == len(by), f"{split_name}: struct X/y length mismatch"
    assert len(aX) == len(bX), f"{split_name}: embeddings and struct counts differ"
    assert np.array_equal(ay, by), f"{split_name}: labels differ between embedding and struct files"

assert_alignment(train_emb, y_train_e, train_struct, y_train_s, "train")
assert_alignment(val_emb, y_val_e, val_struct, y_val_s, "val")
assert_alignment(test_emb, y_test_e, test_struct, y_test_s, "test")

y_train, y_val, y_test = y_train_e, y_val_e, y_test_e

print("\n✅ Alignment checks passed.")

# ------------------------------------------------------------
# 4) Early fusion: concatenate [emb | struct]
# ------------------------------------------------------------
X_train = np.concatenate([train_emb, train_struct], axis=1).astype(np.float32)
X_val   = np.concatenate([val_emb, val_struct], axis=1).astype(np.float32)
X_test  = np.concatenate([test_emb, test_struct], axis=1).astype(np.float32)

print("\nMultimodal feature matrices:")
print("X_train:", X_train.shape)
print("X_val:  ", X_val.shape)
print("X_test: ", X_test.shape)

# ------------------------------------------------------------
# 5) Torch Dataset & DataLoaders
# ------------------------------------------------------------
class NumpyDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.from_numpy(X).float()
        self.y = torch.from_numpy(y).long()

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

train_ds = NumpyDataset(X_train, y_train)
val_ds   = NumpyDataset(X_val, y_val)
test_ds  = NumpyDataset(X_test, y_test)

BATCH_SIZE = 128 if torch.cuda.is_available() else 64
train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)
test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)

# ------------------------------------------------------------
# 6) MLP Model (early fusion classifier)
# ------------------------------------------------------------
input_dim = X_train.shape[1]

class MLP(nn.Module):
    def __init__(self, in_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 2)
        )

    def forward(self, x):
        return self.net(x)

model = MLP(input_dim).to(device)
print("\nMLP input_dim:", input_dim)

# ------------------------------------------------------------
# 7) Loss (class-weighted) + optimizer
# ------------------------------------------------------------
# Class weights computed from train labels (helps imbalance)
class_counts = np.bincount(y_train, minlength=2)
total = class_counts.sum()
weights = total / (2.0 * class_counts + 1e-9)  # inverse frequency-ish
weights_t = torch.tensor(weights, dtype=torch.float32).to(device)

criterion = nn.CrossEntropyLoss(weight=weights_t)
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)

print("Train class counts:", class_counts, "| class weights:", weights)

# ------------------------------------------------------------
# 8) Train with early stopping (on val F1)
# ------------------------------------------------------------
def eval_loader(loader):
    model.eval()
    all_logits = []
    all_y = []
    with torch.no_grad():
        for Xb, yb in loader:
            Xb = Xb.to(device)
            yb = yb.to(device)
            logits = model(Xb)
            all_logits.append(logits.detach().cpu())
            all_y.append(yb.detach().cpu())
    logits = torch.cat(all_logits, dim=0).numpy()
    y_true = torch.cat(all_y, dim=0).numpy()
    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()
    y_pred = probs.argmax(axis=1)

    acc = accuracy_score(y_true, y_pred)
    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average="binary", zero_division=0)
    try:
        roc = roc_auc_score(y_true, probs[:, 1])
    except Exception:
        roc = float("nan")
    cm = confusion_matrix(y_true, y_pred)

    return {"accuracy": acc, "precision": prec, "recall": rec, "f1": f1, "roc_auc": roc, "cm": cm, "probs": probs, "y_true": y_true, "y_pred": y_pred}

EPOCHS = 50
PATIENCE = 6
best_val_f1 = -1.0
best_state = None
pat = 0

history = []

t_train0 = time.perf_counter()
for epoch in range(1, EPOCHS + 1):
    model.train()
    losses = []

    for Xb, yb in train_loader:
        Xb = Xb.to(device)
        yb = yb.to(device)

        optimizer.zero_grad()
        logits = model(Xb)
        loss = criterion(logits, yb)
        loss.backward()
        optimizer.step()
        losses.append(loss.item())

    train_loss = float(np.mean(losses))
    val_metrics = eval_loader(val_loader)

    row = {
        "epoch": epoch,
        "train_loss": train_loss,
        "val_accuracy": val_metrics["accuracy"],
        "val_precision": val_metrics["precision"],
        "val_recall": val_metrics["recall"],
        "val_f1": val_metrics["f1"],
        "val_roc_auc": val_metrics["roc_auc"],
    }
    history.append(row)

    print(f"Epoch {epoch:02d} | train_loss={train_loss:.4f} | val_f1={val_metrics['f1']:.4f} | val_prec={val_metrics['precision']:.4f} | val_rec={val_metrics['recall']:.4f}")

    # early stopping on val F1
    if val_metrics["f1"] > best_val_f1 + 1e-6:
        best_val_f1 = val_metrics["f1"]
        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}
        pat = 0
    else:
        pat += 1
        if pat >= PATIENCE:
            print(f"\nEarly stopping triggered at epoch {epoch}. Best val_f1={best_val_f1:.4f}")
            break

t_train1 = time.perf_counter()
train_time = t_train1 - t_train0
print(f"\nTraining time (s): {train_time:.2f}")

# load best model
if best_state is not None:
    model.load_state_dict(best_state)

# ------------------------------------------------------------
# 9) Final evaluation on TEST
# ------------------------------------------------------------
val_final = eval_loader(val_loader)
test_final = eval_loader(test_loader)

cm = test_final["cm"]
tn, fp, fn, tp = cm.ravel()

print("\nFINAL (VAL) metrics:", {k: float(v) for k, v in val_final.items() if k in ["accuracy","precision","recall","f1","roc_auc"]})
print("FINAL (TEST) metrics:", {k: float(v) for k, v in test_final.items() if k in ["accuracy","precision","recall","f1","roc_auc"]})

print("\nTEST Confusion Matrix:\n", cm)
print(f"TN={tn}, FP={fp}, FN={fn}, TP={tp}")

# ------------------------------------------------------------
# 10) Inference latency (per sample) on TEST
# ------------------------------------------------------------
model.eval()
N_LAT = min(1000, len(X_test))
X_lat = torch.from_numpy(X_test[:N_LAT]).float().to(device)

# warmup
with torch.no_grad():
    _ = model(X_lat[:128])

start = time.perf_counter()
with torch.no_grad():
    _ = model(X_lat)
end = time.perf_counter()

latency_per_sample = (end - start) / N_LAT
print("\nLatency per sample (s):", latency_per_sample)

# ------------------------------------------------------------
# 11) Save outputs
# ------------------------------------------------------------
OUT_DIR = "/content/outputs_multimodal"
os.makedirs(OUT_DIR, exist_ok=True)

# history table
hist_df = pd.DataFrame(history)
hist_df.to_csv(os.path.join(OUT_DIR, "multimodal_training_history.csv"), index=False)

results = {
    "embedding_type": EMB_TYPE,
    "input_dim": int(input_dim),
    "train_time_seconds": float(train_time),
    "best_val_f1": float(best_val_f1),
    "val_metrics": {k: float(v) for k, v in val_final.items() if k in ["accuracy","precision","recall","f1","roc_auc"]},
    "test_metrics": {k: float(v) for k, v in test_final.items() if k in ["accuracy","precision","recall","f1","roc_auc"]},
    "test_confusion_matrix": cm.tolist(),
    "tn": int(tn), "fp": int(fp), "fn": int(fn), "tp": int(tp),
    "latency_per_sample_seconds": float(latency_per_sample)
}

with open(os.path.join(OUT_DIR, "multimodal_results.json"), "w") as f:
    json.dump(results, f, indent=2)

# Save model weights
torch.save(model.state_dict(), os.path.join(OUT_DIR, "multimodal_mlp_state_dict.pt"))

print("\n✅ Multimodal outputs saved to:", OUT_DIR)
print("Files:", sorted(os.listdir(OUT_DIR)))
print("\nReady to write Chapter 3 comparison (baseline vs multimodal).")
